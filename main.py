
import argparse
from file_reader import read_file
from chunking import chunk_text
from indexer import embed_and_store
from retriever import retrieve_relevant_chunks
from qa_chain import generate_answer

def main():
    parser = argparse.ArgumentParser(description="RAG-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    parser.add_argument("--file", type=str, required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (.txt, .pdf, .docx)")
    parser.add_argument("--question", type=str, required=True, help="–í–æ–ø—Ä–æ—Å –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Ñ–∞–π–ª–∞")
    parser.add_argument("--provider", type=str, default="openai", help="LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä: openai | groq | ollama")
    args = parser.parse_args()

    print("üì• –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞...")
    text = read_file(args.file)

    print("‚úÇÔ∏è –ß–∞–Ω–∫–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞...")
    chunks = chunk_text(text)

    print("üì° –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Weaviate...")
    embed_and_store(chunks)

    print("üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤...")
    relevant_chunks = retrieve_relevant_chunks(args.question)

    print(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç {args.provider.upper()}...")
    answer = generate_answer(args.question, relevant_chunks, provider=args.provider)

    print("\n‚úÖ –û—Ç–≤–µ—Ç:")
    print(answer)

if __name__ == "__main__":
    main()
